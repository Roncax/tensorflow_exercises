{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CO-7OBWHkQM_"
   },
   "source": [
    "# Preparation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only for Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8aBP-RcRrJyH"
   },
   "source": [
    "### Unzip the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4672,
     "status": "ok",
     "timestamp": 1574438360777,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "aKNxIITfnC0j",
    "outputId": "ef93ed89-4ce0-4fe9-ac82-121c09d52d62"
   },
   "outputs": [],
   "source": [
    "%%script false\n",
    "# unzip the zip dataset\n",
    "import zipfile\n",
    "!unzip /content/sample_data/a.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false\n",
    "# Install TensorFlow v2 only in Colab\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XvfoCRTXrVjY"
   },
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Lod9JlGGKsV"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import os\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#\n",
    "'''from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False,\n",
    "    min_cuda_compute_capability=None\n",
    ")\n",
    "'''\n",
    "\n",
    "SEED = 1234\n",
    "tf.random.set_seed(SEED)  \n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iHIxAZ85c8Xt"
   },
   "source": [
    "# Upload and preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The split of the validation/training set is automatically done by generators  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-JyYMIdD-toc"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "apply_data_augmentation = True\n",
    "\n",
    "if apply_data_augmentation:\n",
    "    train_data_gen = ImageDataGenerator(rotation_range=10,\n",
    "                                        width_shift_range=10,\n",
    "                                        height_shift_range=10,\n",
    "                                        zoom_range=0.3,\n",
    "                                        horizontal_flip=True,\n",
    "                                        vertical_flip=True,\n",
    "                                        validation_split=0.2,\n",
    "                                        fill_mode='constant',\n",
    "                                        cval=0,\n",
    "                                        rescale=1./255)\n",
    "else:\n",
    "    train_data_gen = ImageDataGenerator(rescale=1./255,\n",
    "                                       validation_split=0.2)\n",
    "\n",
    "test_data_gen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5UQsXajxkKMj"
   },
   "source": [
    "### Create generators to read images from dataset directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**.flow_from_directory:**\n",
    "returns a DirectoryIterator yielding tuples of (x, y) where x is a numpy array containing a batch of images \n",
    "with shape (batch_size, *target_size, channels) and y is a numpy array of corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1091,
     "status": "ok",
     "timestamp": 1574440616445,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "865DKqEo-toj",
    "outputId": "b1be55a0-678e-4214-aa5e-a5a41578e356"
   },
   "outputs": [],
   "source": [
    "dataset_dir = os.path.join(cwd, 'Classification_Dataset')\n",
    "print (dataset_dir)\n",
    "\n",
    "# Batch size\n",
    "bs = 8 \n",
    "\n",
    "# img shape\n",
    "img_h = 256\n",
    "img_w = 256\n",
    "\n",
    "num_classes=20\n",
    "class_list = ['owl', 'galaxy','lightning', 'wine-bottle', 't-shirt', 'waterfall', 'sword', 'school-bus', 'calculator', 'sheet-music', \n",
    "              'airplanes', 'lightbulb', 'skyscraper', 'mountain-bike', 'fireworks', 'computer-monitor', 'bear', 'grand-piano', 'kangaroo', 'laptop']\n",
    " \n",
    "training_dir = os.path.join(dataset_dir, 'training')\n",
    "train_gen = train_data_gen.flow_from_directory(training_dir,\n",
    "                                               classes=class_list,\n",
    "                                               batch_size=bs,\n",
    "                                               class_mode='categorical',\n",
    "                                               shuffle=True,\n",
    "                                               seed=SEED,\n",
    "                                              subset='training') \n",
    "\n",
    "test_dir = os.path.join(dataset_dir,'test')\n",
    "test_gen = test_data_gen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(256, 256),\n",
    "        class_mode=None,\n",
    "        shuffle=False,\n",
    "        batch_size=1)\n",
    "\n",
    "valid_gen = train_data_gen.flow_from_directory(training_dir,\n",
    "                                               batch_size=bs,\n",
    "                                               classes=class_list,\n",
    "                                               class_mode='categorical',\n",
    "                                               shuffle=False,\n",
    "                                               seed=SEED,\n",
    "                                               subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jg6l3MDVkEqQ"
   },
   "source": [
    "## Create Dataset objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tf.data.Dataset.from_generator:**\n",
    "creates a Dataset whose elements are generated by generator.\n",
    "The generator argument must be a callable object that returns an object that supports the iter() protocol (e.g. a generator function). The elements generated by generator must be compatible with the given output_types and (optional) output_shapes arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d9MquFYe-too"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n",
    "\n",
    "train_dataset = train_dataset.repeat()\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen, \n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n",
    "valid_dataset = valid_dataset.repeat()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UdDXHD2tj7cE"
   },
   "source": [
    "**Data augmentation test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Z1tsNTG-tox"
   },
   "outputs": [],
   "source": [
    "%%script false\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca()\n",
    "fig.show()\n",
    "\n",
    "iterator = iter(train_dataset)\n",
    "\n",
    "for _ in range(1000):\n",
    "    augmented_img, target = next(iterator)\n",
    "    augmented_img = augmented_img[0]   # First element\n",
    "    augmented_img = augmented_img * 255  # denormalize\n",
    "    \n",
    "    plt.imshow(np.uint8(augmented_img))\n",
    "    fig.canvas.draw()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generators checks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 398
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 895,
     "status": "error",
     "timestamp": 1574438471207,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "pYc-0zLJq6ND",
    "outputId": "a430fe9d-c910-4fa4-b9f7-5debc552b0cb"
   },
   "outputs": [],
   "source": [
    "%%script false\n",
    "\n",
    "iterator = iter(train_dataset)\n",
    "sample, target = next(iterator)\n",
    "\n",
    "sample = sample[18, ...]  \n",
    "sample = sample * 255  \n",
    "\n",
    "from PIL import Image\n",
    "img = Image.fromarray(np.uint8(sample))\n",
    "img = img.resize([128, 128])\n",
    "img\n",
    "\n",
    "# target[0]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OuVVwc37q03Y"
   },
   "source": [
    "# Model creation and processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Model subclassing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of a convolution block (to simplify the loop later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q3GgTq_w3DHq"
   },
   "outputs": [],
   "source": [
    "class ConvBlock(tf.keras.Model):\n",
    "    def __init__(self, num_filters):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv2d = tf.keras.layers.Conv2D(filters=num_filters,\n",
    "                                             kernel_size=(3, 3),\n",
    "                                             strides=(1, 1), \n",
    "                                             padding='same')\n",
    "        self.activation = tf.keras.layers.ReLU() \n",
    "        self.pooling = tf.keras.layers.MaxPool2D(pool_size=(2, 2))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.conv2d(inputs)\n",
    "        x = self.activation(x)\n",
    "        x = self.pooling(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model using the convblock above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 6\n",
    "start_f = 8\n",
    "num_classes = 20\n",
    "\n",
    "class CNNClassifier(tf.keras.Model):\n",
    "    def __init__(self, depth, start_f, num_classes):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        \n",
    "        self.feature_extractor = tf.keras.Sequential()\n",
    "    \n",
    "        for i in range(depth):\n",
    "            self.feature_extractor.add(ConvBlock(num_filters=start_f))\n",
    "            start_f *= 2\n",
    "            \n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.classifier = tf.keras.Sequential()\n",
    "        self.classifier.add(tf.keras.layers.Dense(units=512, activation='relu'))\n",
    "        self.classifier.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.feature_extractor(inputs)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "model = CNNClassifier(depth=depth,\n",
    "                      start_f=start_f,\n",
    "                      num_classes=num_classes)\n",
    "\n",
    "model.build(input_shape=(None, img_h, img_w, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize created model and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 586,
     "status": "ok",
     "timestamp": 1574438873288,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "jGuVnNUI3IbU",
    "outputId": "da4ebf6e-59bf-4714-d8bd-d146ffe36e57"
   },
   "outputs": [],
   "source": [
    "model.feature_extractor.summary()\n",
    "# model.weights[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n7cbjjHR3141"
   },
   "outputs": [],
   "source": [
    "# Loss\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "# learning rate (used adamax for optimizer)\n",
    "lr = 5e-4\n",
    "optimizer = tf.keras.optimizers.Adamax(learning_rate=lr)\n",
    "\n",
    "# Validation metrics\n",
    "metrics = ['accuracy']\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false\n",
    "\n",
    "callbacks = []\n",
    "\n",
    "early_stop = True\n",
    "if early_stop:\n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    callbacks.append(es_callback)\n",
    "\n",
    "model.fit(x=train_dataset,\n",
    "          epochs=100 \n",
    "          steps_per_epoch=len(train_gen),\n",
    "          validation_data=valid_dataset,\n",
    "          validation_steps=len(valid_gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "exps_dir = os.path.join(cwd, 'challenge_1')\n",
    "if not os.path.exists(exps_dir):\n",
    "    os.makedirs(exps_dir)\n",
    "\n",
    "now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "\n",
    "model_name = 'CNN_challenge1'\n",
    "\n",
    "exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
    "if not os.path.exists(exp_dir):\n",
    "    os.makedirs(exp_dir)\n",
    "    \n",
    "callbacks = []\n",
    "\n",
    "# Model checkpoint\n",
    "ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.makedirs(ckpt_dir)\n",
    "\n",
    "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'), \n",
    "                                                   save_weights_only=True)  # False to save the model directly\n",
    "callbacks.append(ckpt_callback)\n",
    "\n",
    "# Visualize Learning on Tensorboard\n",
    "tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
    "if not os.path.exists(tb_dir):\n",
    "    os.makedirs(tb_dir)\n",
    "    \n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n",
    "                                             profile_batch=0,\n",
    "                                             histogram_freq=1)  \n",
    "callbacks.append(tb_callback)\n",
    "\n",
    "# Early Stopping\n",
    "early_stop = True\n",
    "if early_stop:\n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    callbacks.append(es_callback)\n",
    "\n",
    "model.fit(x=train_dataset,\n",
    "          epochs=100,\n",
    "          steps_per_epoch=len(train_gen),\n",
    "          validation_data=valid_dataset,\n",
    "          validation_steps=len(valid_gen), \n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict_generator(test_gen,\n",
    "                                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything ok?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false\n",
    "\n",
    "prediction.shape\n",
    "print(prediction[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check and write predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image=0\n",
    "relations = {} \n",
    "image_names = []\n",
    "images_class_num= []\n",
    "\n",
    "for img_pred in prediction:\n",
    "    class_num=img_pred.argmax()\n",
    "    image_name = test_gen.filenames[image].replace('sub\\\\','')\n",
    "    relations[image_name] = class_num\n",
    "    image_names.append(image_name)\n",
    "    images_class_num.append(class_num)\n",
    "    image+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write the results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(need to be done twice, don't know why)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "list = [(k, v) for k, v in relations.items()] \n",
    "w = csv.writer(open(\"challenge1_output.csv\", \"w\"))\n",
    "w.writerow([\"Id\", \"Category\"])\n",
    "w.writerows(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of Untitled0.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/Roncax/tensorflow_exercises/blob/master/notebooks/prima_challenge.ipynb",
     "timestamp": 1574440777513
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
