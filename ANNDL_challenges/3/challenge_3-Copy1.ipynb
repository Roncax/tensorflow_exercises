{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3 ANNDL: Image Question - Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach\n",
    "\n",
    "Base: the segmentation exercise from the exercise session of ANNDL\n",
    "Improvement: First some small changes (as the leraning rate, tried some other loss function, add my_IoU). Then i explored some well-known architectures as U-net (by hand) and other using a library (linked above). Then the transfer learning method gave me the better result (i used imagenet weights, with vgg16 and then xception classifier), but the worst performance above the ather methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directory structure\n",
    "\n",
    "- Segmentation_Dataset/\n",
    "    - training/\n",
    "        - images/\n",
    "            - img/\n",
    "                - img1, img2, …, imgN\n",
    "        - masks/\n",
    "            - img/\n",
    "                - mask1, mask2, ... , maskN\n",
    "    - test/\n",
    "        - images/\n",
    "            - img/\n",
    "                - img1, img2, …, imgN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dropout, Lambda\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import pandas as pddef \n",
    "from cv2 import imread\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Check the GPU\n",
    "'''\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False,\n",
    "    min_cuda_compute_capability=None\n",
    ")\n",
    "'''\n",
    "\n",
    "SEED = 1234\n",
    "tf.random.set_seed(SEED)  \n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each question is a dictionary as the following:\n",
    "\n",
    "{\n",
    " - 'question': ...,\n",
    " - 'image_filename': ..., \n",
    " - 'answer': ...\n",
    " \n",
    "}\n",
    "\n",
    "where 'question' is a sentence, e.g., 'How many red objects?', 'image_filename', is the filename of the image the question is referring to, 'answer' is the ground truth (one of {'0', '1', '10', ..., 'no', 'yes'}).\n",
    "\n",
    "Test questions have an additional key that is a 'question_id' to uniquely identify your solution when submitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = os.path.join(cwd, 'dataset_vqa')\n",
    "\n",
    "# Batch size\n",
    "bs = 128\n",
    "\n",
    "# img shape\n",
    "img_h = 320\n",
    "img_w = 480\n",
    "\n",
    "num_classes = 13\n",
    "\n",
    "classes = {'0': 0,\n",
    "    '1': 1,\n",
    "    '10': 2,\n",
    "    '2': 3,\n",
    "    '3': 4,\n",
    "    '4': 5,\n",
    "    '5': 6,\n",
    "    '6': 7,\n",
    "    '7': 8,\n",
    "    '8': 9,\n",
    "    '9': 10,\n",
    "    'no': 11,\n",
    "    'yes': 12}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "train_path = '/Git/tensorflow_exercises/ANNDL_challenges/3/dataset_vqa/train/images'\n",
    "test_path = '/Git/tensorflow_exercises/ANNDL_challenges/3/dataset_vqa/test/images'\n",
    "\n",
    "d=[]\n",
    "train_dict=[]\n",
    "test_dict=[]\n",
    "valid_dict = []\n",
    "x = 0\n",
    "ind = 0\n",
    "all_questions = []\n",
    "\n",
    "# Read the json into Dictionaries\n",
    "with open('/Git/tensorflow_exercises/ANNDL_challenges/3/dataset_vqa/test_data.json', 'r') as f:\n",
    "      test_data = json.load(f)\n",
    "f.close()\n",
    "\n",
    "with open('/Git/tensorflow_exercises/ANNDL_challenges/3/dataset_vqa/train_data.json', 'r') as f:\n",
    "      train_data = json.load(f)\n",
    "f.close()\n",
    "\n",
    "for key in train_data[\"questions\"]:\n",
    "    all_questions.append(key['question'])\n",
    "    d.append(x)\n",
    "    x += 1\n",
    "    \n",
    "for key in test_data[\"questions\"]:\n",
    "    all_questions.append(key['question'])\n",
    "    test_dict.append(ind)\n",
    "    ind += 1\n",
    "    \n",
    "valid_dict = d[int(len(d)*0.8):]\n",
    "train_dict = d[:int(len(d)*0.8)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit tokenizer on the training questions\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(all_questions)\n",
    "vocab_size = len(tokenizer.word_index) + 1  # We add one because the Keras Tokenizer reserves index 0 and never uses it.\n",
    "\n",
    "def string_to_BOW(train_questions):\n",
    "    # Convert questions to BOW\n",
    "    train_X_seqs = tokenizer.texts_to_matrix(train_questions)\n",
    "    return train_X_seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare TEST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_list = []\n",
    "def get_train(id_number):\n",
    "    \n",
    "    image_info = test_data[\"questions\"][id_number]\n",
    "    image_name = image_info[\"image_filename\"]\n",
    "    img = imread(test_path + \"/\" + image_name)\n",
    "    img_question = image_info[\"question\"]\n",
    "    return img, img_question\n",
    "\n",
    "\n",
    "def test_generator(files):\n",
    "    i=0\n",
    "    while True:         \n",
    "        batch_input = []\n",
    "        batch_question = []\n",
    "        \n",
    "        input_path = files[i]\n",
    "        i+=1\n",
    "        \n",
    "        file_list.append(input_path)\n",
    "        input_vqa, input_question_vqa = get_train(input_path)\n",
    "        input_vqa = input_vqa / 255\n",
    "        batch_input.append(input_vqa)\n",
    "        batch_question.append(input_question_vqa)\n",
    "\n",
    "        batch_question_encoded = string_to_BOW(batch_question)  \n",
    "        \n",
    "        np_batch_input = np.array(batch_input)\n",
    "        np_batch_question = np.array(batch_question_encoded, dtype=np.uint8)\n",
    "        \n",
    "        yield [np_batch_input, np_batch_question]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input(id_number):\n",
    "    image_info = train_data[\"questions\"][id_number]\n",
    "    image_name = image_info[\"image_filename\"]\n",
    "    img = imread(train_path + \"/\" + image_name)\n",
    "    img_question = image_info[\"question\"]\n",
    "    \n",
    "    img_answer = image_info[\"answer\"]\n",
    "    img_answer = classes[img_answer]\n",
    "    return img, img_question, img_answer\n",
    "\n",
    "def image_generator(files, batch_size = bs):\n",
    "\n",
    "        \n",
    "    while True:\n",
    "        batch_input = []\n",
    "        batch_answer = []\n",
    "        batch_question = []\n",
    "        batch_paths = np.random.choice(a = files, \n",
    "                                        size = batch_size,\n",
    "                                        replace=False)\n",
    "        \n",
    "        # Read in each input, perform preprocessing and get labels          \n",
    "        for input_path in batch_paths: \n",
    "            input_vqa, input_question_vqa, answer_vqa = get_input(input_path)\n",
    "            input_vqa = input_vqa / 255\n",
    "            batch_input.append(input_vqa)\n",
    "            batch_question.append(input_question_vqa)\n",
    "            batch_answer.append(answer_vqa) \n",
    "\n",
    "        batch_question_encoded = string_to_BOW(batch_question)      \n",
    "\n",
    "        np_batch_question = np.array(batch_question_encoded, dtype=np.uint8)\n",
    "\n",
    "        \n",
    "        yield [batch_input, np_batch_question], batch_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual generator (+ tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\niterator=iter(test_gen)\\ninputs, answers = next(iterator)\\n\\nprint(inputs[1][1])\\nprint(inputs[0][1])\\nprint(answers)\\nprint(file_list)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen = image_generator(train_dict)\n",
    "valid_gen = image_generator(valid_dict)\n",
    "test_gen = test_generator(test_dict)\n",
    "\"\"\"\n",
    "iterator=iter(test_gen)\n",
    "inputs, answers = next(iterator)\n",
    "\n",
    "print(inputs[1][1])\n",
    "print(inputs[0][1])\n",
    "print(answers)\n",
    "print(file_list)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 320, 480, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 320, 480, 8)  224         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 160, 240, 8)  0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 160, 240, 16) 1168        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 80, 120, 16)  0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 71)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 153600)       0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           2304        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           4915232     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           1056        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 32)           0           dense[0][0]                      \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           1056        multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 13)           429         dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,921,469\n",
      "Trainable params: 4,921,469\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Multiply\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "\n",
    "# The CNN\n",
    "im_input = Input(shape=(img_h, img_w, 3), dtype='float32')\n",
    "x1 = Conv2D(8, 3, padding='same')(im_input)\n",
    "x1 = MaxPooling2D()(x1)\n",
    "x1 = Conv2D(16, 3, padding='same')(x1)\n",
    "x1 = MaxPooling2D()(x1)\n",
    "x1 = Flatten()(x1)\n",
    "# Add a final fully-connected layer after the CNN for good measure\n",
    "x1 = Dense(32, activation='tanh')(x1)\n",
    "\n",
    "# The question network\n",
    "q_input = Input(shape=(vocab_size,), dtype='uint8')\n",
    "x2 = Dense(32, activation='tanh')(q_input)\n",
    "x2 = Dense(32, activation='tanh')(x2)\n",
    "\n",
    "# Combine CNN and RNN to create the final model\n",
    "out = Multiply()([x1, x2])\n",
    "out = Dense(32, activation='tanh')(out)\n",
    "out = Dense(13, activation='softmax')(out)\n",
    "\n",
    "vqa_model = Model(inputs=[im_input, q_input], outputs=out)\n",
    "vqa_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false \n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "\n",
    "# Define CNN for Image Input\n",
    "vision_model = Sequential()\n",
    "vision_model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(img_h, img_w, 3)))\n",
    "vision_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "vision_model.add(MaxPooling2D((2, 2)))\n",
    "vision_model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "vision_model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "vision_model.add(MaxPooling2D((2, 2)))\n",
    "vision_model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "vision_model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "vision_model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "vision_model.add(MaxPooling2D((2, 2)))\n",
    "vision_model.add(Flatten())\n",
    "\n",
    "image_input = Input(shape=(img_h, img_w, 3))\n",
    "encoded_image = vision_model(image_input)\n",
    "\n",
    "# Define RNN for language input\n",
    "question_input = Input(shape=(vocab_size,) , dtype='uint8')\n",
    "embedded_question = Embedding(input_dim=10000, output_dim=1, input_length=vocab_size)(question_input)\n",
    "encoded_question = LSTM(256)(embedded_question)\n",
    "\n",
    "# Combine CNN and RNN to create the final model\n",
    "merged = tf.keras.layers.concatenate([encoded_question, encoded_image])\n",
    "output = Dense(1000, activation='softmax')(merged)\n",
    "vqa_model = Model(inputs=[image_input, question_input], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "loss = 'sparse_categorical_crossentropy'\n",
    "lr = 1e-3\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "# metrics = ['accuracy']\n",
    "metrics = ['sparse_categorical_accuracy']\n",
    "\n",
    "vqa_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 113/1621 [=>............................] - ETA: 1:00:06 - loss: 1.5870 - sparse_categorical_accuracy: 0.3551"
     ]
    }
   ],
   "source": [
    "# Include the epoch in the file name (uses `str.format`)\n",
    "checkpoint_path = \"challenge_3/{epoch:02d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True,\n",
    "    save_freq='epoch')\n",
    "\n",
    "# 207594\n",
    "# 51899\n",
    "vqa_model.fit_generator(train_gen, \n",
    "              steps_per_epoch= int(207594/bs), \n",
    "              epochs=10, \n",
    "              verbose=1, \n",
    "              callbacks=None, \n",
    "              validation_data= valid_gen, \n",
    "              validation_steps= int(51899/bs), \n",
    "              validation_freq=1, \n",
    "              class_weight=None, \n",
    "              max_queue_size=10, \n",
    "              workers=1, \n",
    "              use_multiprocessing=False, \n",
    "              shuffle=False, \n",
    "              initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = vqa_model.predict_generator(test_gen,\n",
    "                                        verbose=1,\n",
    "                                        steps=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.shape\n",
    "file_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "for i in range(3000):\n",
    "    results_dict[file_list[i]] = prediction[i].argmax()\n",
    "print(len(results_dict))\n",
    "    \n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def create_csv(results, results_dir='./'):\n",
    "\n",
    "    csv_fname = 'results_'\n",
    "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
    "\n",
    "    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n",
    "\n",
    "        f.write('Id,Category\\n')\n",
    "\n",
    "        for key, value in results.items():\n",
    "            f.write(str(key) + ',' + str(value) + '\\n')\n",
    "            \n",
    "create_csv(results_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
